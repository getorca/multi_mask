{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import RobertaTokenizer, RobertaForMaskedLM\n",
    "import torch\n",
    "\n",
    "tokenizer = RobertaTokenizer.from_pretrained('roberta-base')\n",
    "model = RobertaForMaskedLM.from_pretrained('roberta-base')\n",
    "\n",
    "sentence = \"Tom has fully ___ ___ ___ ___ ___ ___ illness.\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<unk>'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.unk_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Sentence:  Tom has fully <mask> <mask> <mask> <mask> <mask> <mask> illness.\n",
      "Original Sentence replaced with mask:  Tom has fully <mask> <mask> <mask> <mask> <mask> <mask> illness.\n",
      "\n",
      "\n",
      "tensor([[    0, 15691,    34,  1950, 50264, 50264, 50264, 50264, 50264, 50264,\n",
      "          5467,     4,     2]])\n",
      "tensor([[[30.8177, -4.3517, 17.8006,  ...,  0.2488,  2.9159, 11.5837],\n",
      "         [ 1.6616, -4.2776,  9.5994,  ..., -5.5591, -3.4594,  0.0512],\n",
      "         [-0.3035, -3.6131,  7.9517,  ..., -1.7542, -1.1053,  3.3645],\n",
      "         ...,\n",
      "         [-3.5634, -4.8674,  8.0275,  ..., -6.8150, -5.1172, -2.5712],\n",
      "         [14.3591, -5.1044, 16.8345,  ..., -3.7020, -1.5309,  6.7080],\n",
      "         [11.4474, -3.8683, 28.1128,  ..., -0.4098, -1.9798,  8.0904]]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' recovered the the of of his'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "def get_prediction (sent):\n",
    "    \n",
    "    token_ids = tokenizer.encode(sent, return_tensors='pt')\n",
    "    masked_position = (token_ids.squeeze() == tokenizer.mask_token_id).nonzero()\n",
    "    masked_pos = [mask.item() for mask in masked_position ]\n",
    "\n",
    "    with torch.no_grad():\n",
    "        output = model(token_ids)\n",
    "\n",
    "    print(token_ids)\n",
    "    print(output[0])\n",
    "\n",
    "    last_hidden_state = output[0].squeeze()\n",
    "    # print(last_hidden_state)\n",
    "    list_of_list =[]\n",
    "    for index, mask_index in enumerate(masked_pos):\n",
    "        mask_hidden_state = last_hidden_state[mask_index]\n",
    "        # print(mask_hidden_state)\n",
    "        idx = torch.topk(mask_hidden_state, k=5, dim=0)[1]\n",
    "        words = [tokenizer.decode(i.item()).strip() for i in idx]\n",
    "        list_of_list.append(words)\n",
    "        # print (\"Mask \",index+1,\"Guesses : \",words)\n",
    "    \n",
    "    best_guess = \"\"\n",
    "    for j in list_of_list:\n",
    "        best_guess = best_guess+\" \"+j[0]\n",
    "        \n",
    "    return best_guess\n",
    "\n",
    "\n",
    "print (\"Original Sentence: \",sentence)\n",
    "sentence = sentence.replace(\"___\",\"<mask>\")\n",
    "print (\"Original Sentence replaced with mask: \",sentence)\n",
    "print (\"\\n\")\n",
    "\n",
    "prediction_blanks = get_prediction(sentence)\n",
    "\n",
    "prediction_blanks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[    0, 15691,    34,  1950, 50264, 50264, 50264, 50264, 50264, 50264,\n",
      "          5467,     4,     2]])\n",
      "[tensor(4), tensor(5), tensor(6), tensor(7), tensor(8), tensor(9)]\n",
      "tensor(4609)\n",
      "tensor([[    0, 15691,    34,  1950,  4609, 50264, 50264, 50264, 50264, 50264,\n",
      "          5467,     4,     2]])\n",
      " recovered\n",
      "<s>Tom has fully recovered<mask><mask><mask><mask><mask> illness.</s>\n",
      "tensor(31)\n",
      "tensor([[    0, 15691,    34,  1950,  4609,    31, 50264, 50264, 50264, 50264,\n",
      "          5467,     4,     2]])\n",
      " from\n",
      "<s>Tom has fully recovered from<mask><mask><mask><mask> illness.</s>\n",
      "tensor(39)\n",
      "tensor([[    0, 15691,    34,  1950,  4609,    31,    39, 50264, 50264, 50264,\n",
      "          5467,     4,     2]])\n",
      " his\n",
      "<s>Tom has fully recovered from his<mask><mask><mask> illness.</s>\n",
      "tensor(251)\n",
      "tensor([[    0, 15691,    34,  1950,  4609,    31,    39,   251, 50264, 50264,\n",
      "          5467,     4,     2]])\n",
      " long\n",
      "<s>Tom has fully recovered from his long<mask><mask> illness.</s>\n",
      "tensor(12)\n",
      "tensor([[    0, 15691,    34,  1950,  4609,    31,    39,   251,    12, 50264,\n",
      "          5467,     4,     2]])\n",
      "-\n",
      "<s>Tom has fully recovered from his long-<mask> illness.</s>\n",
      "tensor(1279)\n",
      "tensor([[    0, 15691,    34,  1950,  4609,    31,    39,   251,    12,  1279,\n",
      "          5467,     4,     2]])\n",
      "term\n",
      "<s>Tom has fully recovered from his long-term illness.</s>\n"
     ]
    }
   ],
   "source": [
    "def get_prediction_2(sentence):\n",
    "    \n",
    "    inputs = tokenizer(sentence, return_tensors=\"pt\")\n",
    "    \n",
    "    print(inputs[\"input_ids\"])\n",
    "    masked_positions = [x for x in (inputs[\"input_ids\"] == tokenizer.mask_token_id)[0].nonzero(as_tuple=True)[0]]\n",
    "    print(masked_positions  )\n",
    "    with torch.no_grad():\n",
    "        logits = model(**inputs).logits\n",
    "    \n",
    "    for mask_idx in masked_positions:\n",
    "        predicted_token_id = logits[0, mask_idx].argmax(axis=-1)\n",
    "        print(predicted_token_id)\n",
    "        inputs[\"input_ids\"][0][mask_idx] = predicted_token_id\n",
    "        print(inputs[\"input_ids\"])\n",
    "        print(tokenizer.decode(predicted_token_id))\n",
    "        with torch.no_grad():\n",
    "            logits = model(**inputs).logits\n",
    "        # mask_word = tokenizer.convert_ids_to_tokens([inputs[\"input_ids\"][0][mask].item()])\n",
    "        # mask_word_logits = logits[0, mask]\n",
    "        # mask_word_prob = torch.softmax(mask_word_logits, dim=0)[mask_word]\n",
    "        # print(f\"Prediction for '{mask_word[0]}': {mask_word[0]} with probability {mask_word_prob.item()}\")\n",
    "        # top_5 = torch.topk(mask_word_logits, 5)\n",
    "        # for i in range(5):\n",
    "        #     word = tokenizer.convert_ids_to_tokens([top_5.indices[i].item()])\n",
    "        #     print(f\"Guess {i+1}: '{word[0]}' with probability {top_5.values[i].item()}\")\n",
    "        # print()\n",
    "        print(tokenizer.decode(inputs[\"input_ids\"][0]))\n",
    "    # print(logits)\n",
    "    \n",
    "get_prediction_2(sentence.replace(\"___\",\"<mask>\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hf_gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
